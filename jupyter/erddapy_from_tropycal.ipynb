{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting all the input variables\n",
    "\n",
    "storm_name = \"dorian\"\n",
    "storm_year = 2019\n",
    "storm_lowerLat= 40\n",
    "\n",
    "latExtension = 2\n",
    "lonExtension = 2\n",
    "dateExtension = 2\n",
    "\n",
    "focus_variable = \"wind_spd_avg\"\n",
    "var_units = \"(m s-1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in ibtracs data\n",
      "--> Completed reading in ibtracs data (9.91 seconds)\n",
      "Using no lon bounds\n"
     ]
    }
   ],
   "source": [
    "# Getting storm data and matching ERDDAP datasets around the storm (time and space)\n",
    "\n",
    "import tropycal.tracks as tracks\n",
    "import pandas as pd\n",
    "from erddapy import ERDDAP\n",
    "from datetime import timedelta\n",
    "\n",
    "basin = tracks.TrackDataset(basin='north_atlantic', source='ibtracs')\n",
    "storm = basin.get_storm((storm_name,storm_year))\n",
    "\n",
    "# Coordinate selector throws an error when using with Fiona but still generates the graph\n",
    "storm = storm.sel(lat=[storm_lowerLat,None])\n",
    "\n",
    "storm_df = storm.to_dataframe()\n",
    "\n",
    "min_lat = storm_df['lat'].min()\n",
    "min_lon = storm_df['lon'].min()\n",
    "max_lat = storm_df['lat'].max()\n",
    "max_lon = storm_df['lon'].max()\n",
    "start_date = storm_df.min()['date']\n",
    "end_date = storm_df.max()['date']\n",
    "\n",
    "# Get datasets matching time and location criteria, plus a buffer zone\n",
    "\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\"\n",
    ")\n",
    "\n",
    "e.dataset_id = \"allDatasets\"\n",
    "\n",
    "e.variables = [\n",
    "    \"datasetID\",\n",
    "    \"minLongitude\",\n",
    "    \"maxLongitude\",\n",
    "    \"minLatitude\",\n",
    "    \"maxLatitude\",\n",
    "    \"minTime\",\n",
    "    \"maxTime\"\n",
    "]\n",
    "\n",
    "e.constraints = {\n",
    "    \"minTime<=\": end_date + timedelta(days = dateExtension),\n",
    "    \"maxTime>=\": start_date- timedelta(days = dateExtension),\n",
    "    \"minLatitude>=\": min_lat - latExtension,\n",
    "    \"maxLatitude<=\": max_lat + latExtension,\n",
    "    \"minLongitude>=\": min_lon - lonExtension,\n",
    "    \"maxLongitude<=\": max_lon + lonExtension,\n",
    "}\n",
    "\n",
    "datasets_df = e.to_pandas(\n",
    "    parse_dates=True,\n",
    ").dropna()\n",
    "datasets = set(datasets_df[\"datasetID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SMA_saint_john_cruise_terminal', 'SMA_halifax', 'sma_negl_black_tickle_nlqu0003', 'sma_negl_north_west_river_nlqu0007', 'SMA_halifax_pier9c', 'DFO_Sutron_KLUMI', 'SMA_red_island_shoal', 'SMA_Holyrood_Buoy2', 'SMA_halifax_fairview', 'SMA_saint_john', 'SMA_saint_john_wharf', 'cna_werc_weather_10-min_avg', 'SMA_MouthofPlacentiaBayBuoy', 'SMA_Fortune_Bay_Buoy', 'SMA_port_aux_basqes_wharf', 'sma_negl_red_bay_nlqu0005', 'SMA_halifax_anemometer1', 'SMA_port_aux_basques', 'sma_negl_cartwright_junction_nlqu0004', 'SMA_holyrood_wharf']\n"
     ]
    }
   ],
   "source": [
    "# Narrow down datasets that contain the focused variable\n",
    "# Some datasets may not match at certain points if their coverage is inconsistent\n",
    "\n",
    "matching_datasets = []\n",
    "for dataset in datasets:\n",
    "    info_url = e.get_info_url(dataset_id = dataset, response = \"csv\")\n",
    "    dataset_info = pd.read_csv(info_url)\n",
    "\n",
    "    variable_names = set(dataset_info[\"Variable Name\"].unique())\n",
    "    if focus_variable in variable_names:\n",
    "         matching_datasets.append(dataset)\n",
    "\n",
    "print(matching_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA_saint_john_cruise_terminal\n",
      "2019-09-08T12:00:00Z\n",
      "5.2\n",
      "-\n",
      "SMA_halifax\n",
      "2019-09-08T11:53:01Z\n",
      "7.8\n",
      "-\n",
      "sma_negl_black_tickle_nlqu0003\n",
      "2019-09-08T11:52:00Z\n",
      "10.861111\n",
      "-\n",
      "sma_negl_north_west_river_nlqu0007\n",
      "2019-09-08T11:16:00Z\n",
      "3.75\n",
      "-\n",
      "SMA_halifax_pier9c\n",
      "couldn't find info for the given dataset\n",
      "-\n",
      "DFO_Sutron_KLUMI\n",
      "couldn't find info for the given dataset\n",
      "-\n",
      "SMA_red_island_shoal\n",
      "2019-09-08T11:55:00Z\n",
      "14.1\n",
      "-\n",
      "SMA_Holyrood_Buoy2\n",
      "2019-09-08T11:53:00Z\n",
      "13.1\n",
      "-\n",
      "SMA_halifax_fairview\n",
      "2019-09-08T11:50:00Z\n",
      "4.8\n",
      "-\n",
      "SMA_saint_john\n",
      "2019-09-08T11:53:01Z\n",
      "8.0\n",
      "-\n",
      "SMA_saint_john_wharf\n",
      "2019-09-08T11:59:36Z\n",
      "6.1\n",
      "-\n",
      "cna_werc_weather_10-min_avg\n",
      "2019-09-08T12:00:00Z\n",
      "couldn't find info for the given dataset\n",
      "-\n",
      "SMA_MouthofPlacentiaBayBuoy\n",
      "couldn't find info for the given dataset\n",
      "-\n",
      "SMA_Fortune_Bay_Buoy\n",
      "2019-09-08T11:53:41Z\n",
      "11.9\n",
      "-\n",
      "SMA_port_aux_basqes_wharf\n",
      "2019-09-08T11:59:15Z\n",
      "8.3\n",
      "-\n",
      "sma_negl_red_bay_nlqu0005\n",
      "2019-09-08T11:52:00Z\n",
      "14.25\n",
      "-\n",
      "SMA_halifax_anemometer1\n",
      "couldn't find info for the given dataset\n",
      "-\n",
      "SMA_port_aux_basques\n",
      "2019-09-08T11:54:01Z\n",
      "21.2\n",
      "-\n",
      "sma_negl_cartwright_junction_nlqu0004\n",
      "2019-09-08T11:52:00Z\n",
      "7.25\n",
      "-\n",
      "SMA_holyrood_wharf\n",
      "2019-09-08T11:51:45Z\n",
      "4.3\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Find most recent values for focus var given a time point\n",
    "\n",
    "selected_time=  start_date + timedelta(days = 1)\n",
    "matching_points = pd.DataFrame()\n",
    "\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\",\n",
    ")\n",
    "\n",
    "for dataset in matching_datasets:\n",
    "\n",
    "    e.dataset_id = dataset\n",
    "    print(dataset)\n",
    "    \n",
    "    e.constraints = {\n",
    "        \"time<=\": selected_time,\n",
    "        \"time>=\": selected_time - timedelta(hours = 6)\n",
    "    }\n",
    "        \n",
    "    e.variables = [\"time\", \"longitude\", \"latitude\", focus_variable]\n",
    "\n",
    "    try:\n",
    "        buoy_data= e.to_pandas(\n",
    "            parse_dates=True,\n",
    "        ).dropna()\n",
    "        recent_row = buoy_data.tail(1)\n",
    "        print(recent_row[\"time (UTC)\"].iloc[0])\n",
    "        print(recent_row[focus_variable + \" \" + var_units].iloc[0])\n",
    "        matching_points = pd.concat([matching_points, recent_row.loc[:]]).reset_index(drop=True)\n",
    "    except:\n",
    "        print(\"couldn't find info for the given dataset\")\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              time (UTC)  longitude (degrees_east)  latitude (degrees_north)  \\\n",
      "0   2019-09-08T12:00:00Z                -66.061167                 45.266833   \n",
      "1   2019-09-08T11:53:01Z                -63.544467                 44.555900   \n",
      "2   2019-09-08T11:52:00Z                -55.779680                 53.463710   \n",
      "3   2019-09-08T11:16:00Z                -60.149180                 53.537400   \n",
      "4   2019-09-08T11:55:00Z                -54.122208                 47.318377   \n",
      "5   2019-09-08T11:53:00Z                -53.108107                 47.461835   \n",
      "6   2019-09-08T11:50:00Z                -63.627217                 44.664167   \n",
      "7   2019-09-08T11:53:01Z                -66.113767                 45.197167   \n",
      "8   2019-09-08T11:59:36Z                -66.045167                 45.268867   \n",
      "9   2019-09-08T11:53:41Z                -55.498453                 47.260857   \n",
      "10  2019-09-08T11:59:15Z                -59.139467                 47.574533   \n",
      "11  2019-09-08T11:52:00Z                -56.527070                 51.741780   \n",
      "12  2019-09-08T11:54:01Z                -59.100398                 47.562842   \n",
      "13  2019-09-08T11:52:00Z                -58.453140                 52.719830   \n",
      "14  2019-09-08T11:51:45Z                -53.134950                 47.388657   \n",
      "\n",
      "    wind_spd_avg (m s-1)  \n",
      "0               5.200000  \n",
      "1               7.800000  \n",
      "2              10.861111  \n",
      "3               3.750000  \n",
      "4              14.100000  \n",
      "5              13.100000  \n",
      "6               4.800000  \n",
      "7               8.000000  \n",
      "8               6.100000  \n",
      "9              11.900000  \n",
      "10              8.300000  \n",
      "11             14.250000  \n",
      "12             21.200000  \n",
      "13              7.250000  \n",
      "14              4.300000  \n"
     ]
    }
   ],
   "source": [
    "print(matching_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots  for matching datasets\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\",\n",
    ")\n",
    "\n",
    "for dataset in matching_datasets:\n",
    "\n",
    "    # Still keeps generating graph after dataset fails for some reason?\n",
    "\n",
    "    e.dataset_id = dataset\n",
    "\n",
    "    e.constraints = {\n",
    "        \"time>=\": start_date - timedelta(days = 2),\n",
    "        \"time<=\": end_date + timedelta(days = 2)\n",
    "    }\n",
    "\n",
    "    e.variables = [\"time\", \"longitude\", \"latitude\", focus_variable]\n",
    "\n",
    "    try:\n",
    "        buoy_data= e.to_pandas(\n",
    "            parse_dates=True,\n",
    "        ).dropna()\n",
    "        buoy_data.plot(x='time (UTC)', y=focus_variable + ' ' + var_units, title=dataset)\n",
    "    except:\n",
    "        print(\"Data does not exist for %s\", dataset) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hurricane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
