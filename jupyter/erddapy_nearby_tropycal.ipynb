{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting all the input variables\n",
    "\n",
    "storm_name = \"dorian\"\n",
    "storm_year = 2019\n",
    "storm_lowerLat= 40\n",
    "\n",
    "# How many days before / after the storm dates to get data for graphing\n",
    "dateExtension = 2\n",
    "\n",
    "focus_variable = \"wind_spd_avg\"\n",
    "var_units = \"(m s-1)\"\n",
    "\n",
    "# Time in hours after the first measurement of the storm to observe\n",
    "storm_time_offset = 8\n",
    "\n",
    "# Time in hours to go back for a station's measurement\n",
    "# Change to just have the minimum time be the start of the storm?\n",
    "storm_time_bounds = 1\n",
    "\n",
    "# Color map style to use for the output station data\n",
    "color_map = 'Blues'\n",
    "\n",
    "# Buoys to exclude (for demoing purposes these either give odd values or overlap with other markers)\n",
    "#exclude=  [\"sma_negl_cartwright_junction_nlqu0004\", \"SMA_halifax_fairview\", \"SMA_port_aux_basqes_wharf\"]\n",
    "exclude= []\n",
    "\n",
    "#interest_variables = [\"wind_spd\", \"wave_ht\", \"pressure\"]\n",
    "# Categories: Wind, Surface Waves, Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting storm data and matching ERDDAP datasets around the storm (time and space)\n",
    "\n",
    "import tropycal.tracks as tracks\n",
    "import pandas as pd\n",
    "from erddapy import ERDDAP\n",
    "from datetime import timedelta\n",
    "\n",
    "basin = tracks.TrackDataset(basin='north_atlantic', source='ibtracs')\n",
    "storm = basin.get_storm((storm_name,storm_year))\n",
    "\n",
    "# Coordinate selector throws an error when using with Fiona but still generates the graph\n",
    "storm = storm.sel(lat=[storm_lowerLat,None])\n",
    "\n",
    "storm_dict = storm.interp().to_dict()\n",
    "\n",
    "# Some fields are left empty after interpolation, so need to only include ones that will have values\n",
    "storm_dict_cut = {\n",
    "    'date':storm_dict['date'],\n",
    "    'type':storm_dict['type'],\n",
    "    'lat':storm_dict['lat'],\n",
    "    'lon':storm_dict['lon'],\n",
    "}\n",
    "\n",
    "#storm_df = storm.to_dataframe()\n",
    "storm_df = pd.DataFrame.from_dict(storm_dict_cut)\n",
    "\n",
    "storm_df['lon'] = storm_df['lon'].apply(lambda x: x-360.0)\n",
    "\n",
    "start_date = storm_df.min()['date']\n",
    "end_date = storm_df.max()['date']\n",
    "\n",
    "# Get datasets matching time and location criteria, plus a buffer zone\n",
    "\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\"\n",
    ")\n",
    "\n",
    "e.dataset_id = \"allDatasets\"\n",
    "\n",
    "e.variables = [\n",
    "    \"datasetID\",\n",
    "    \"minTime\",\n",
    "    \"maxTime\"\n",
    "]\n",
    "\n",
    "e.constraints = {\n",
    "    \"minTime<=\": end_date + timedelta(days = dateExtension),\n",
    "    \"maxTime>=\": start_date- timedelta(days = dateExtension)\n",
    "}\n",
    "\n",
    "datasets_df = e.to_pandas(\n",
    "    parse_dates=True,\n",
    ").dropna()\n",
    "datasets = set(datasets_df[\"datasetID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow down datasets that contain the focused variable\n",
    "# Some datasets may not match at certain points if their coverage is inconsistent\n",
    "\n",
    "matching_datasets = []\n",
    "for dataset in datasets:\n",
    "    info_url = e.get_info_url(dataset_id = dataset, response = \"csv\")\n",
    "    dataset_info = pd.read_csv(info_url)\n",
    "\n",
    "    variable_names = set(dataset_info[\"Variable Name\"].unique())\n",
    "    if focus_variable in variable_names and dataset not in exclude:\n",
    "         matching_datasets.append(dataset)\n",
    "\n",
    "print(matching_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most recent values for focus var given a time point\n",
    "\n",
    "selected_time=  start_date + timedelta(hours = storm_time_offset)\n",
    "matching_points = pd.DataFrame()\n",
    "\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\",\n",
    ")\n",
    "\n",
    "for dataset in matching_datasets:\n",
    "\n",
    "    e.dataset_id = dataset\n",
    "    print(dataset)\n",
    "    \n",
    "    e.constraints = {\n",
    "        \"time<=\": selected_time,\n",
    "        \"time>=\": selected_time - timedelta(hours = storm_time_bounds)\n",
    "    }\n",
    "        \n",
    "    e.variables = [\"time\", \"longitude\", \"latitude\", focus_variable]\n",
    "\n",
    "    try:\n",
    "        buoy_data= e.to_pandas(\n",
    "            parse_dates=True,\n",
    "        ).dropna()\n",
    "        recent_row = buoy_data.tail(1)\n",
    "        print(recent_row[\"time (UTC)\"].iloc[0])\n",
    "        print(recent_row[focus_variable + \" \" + var_units].iloc[0])\n",
    "        recent_row.insert(0, \"dataset\", dataset)\n",
    "        matching_points = pd.concat([matching_points, recent_row.loc[:]]).reset_index(drop=True)\n",
    "    except:\n",
    "        print(\"couldn't find info for the given dataset for the given time\")\n",
    "    print(\"-\")\n",
    "matching_points.set_index('dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "try:\n",
    "    import cartopy.feature as cfeature\n",
    "    from cartopy import crs as ccrs\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "except:\n",
    "    warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
    "\n",
    "proj = ccrs.Mercator(central_longitude=305, min_latitude=40, max_latitude=54)\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=proj), figsize=(12,12))\n",
    "ax.set_extent([312 , 285, 40, 54], crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "ax.add_feature(cfeature.BORDERS, zorder=10)\n",
    "ax.add_feature(cfeature.COASTLINE, zorder=10)\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, color='black', alpha=.5, linestyle='--', draw_labels=True)\n",
    "\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "\n",
    "map_storm_line = ax.plot(storm_df['lon'],storm_df['lat'], linestyle = 'dashed', linewidth =3, c= 'black', transform=ccrs.PlateCarree())\n",
    "\n",
    "mask = (storm_df['date'] <= selected_time) & (storm_df['date'] > (selected_time - timedelta(hours=  storm_time_bounds)))\n",
    "storm_position = storm_df.loc[mask].tail(1)\n",
    "map_storm_position= ax.scatter(x=storm_position['lon'].iloc[0], y=storm_position['lat'].iloc[0], c= 'red', \n",
    "           marker = '*', s=600, transform=ccrs.PlateCarree())\n",
    "\n",
    "map_stations = ax.scatter(x=matching_points['longitude (degrees_east)'], y=matching_points['latitude (degrees_north)'],  \n",
    "           c=matching_points[focus_variable + \" \" + var_units], cmap =  color_map, marker = 'v', s=200, transform=ccrs.PlateCarree(), alpha= 1,\n",
    "           edgecolors='black')\n",
    "\n",
    "# TODO: Fix issue where colormap sets to minimum instead of at 0 (or vice versa)\n",
    "\n",
    "norm = colors.Normalize(matching_points[focus_variable + \" \" + var_units].min(), \n",
    "                        matching_points[focus_variable + \" \" + var_units].max())\n",
    "fig.colorbar(cm.ScalarMappable(norm= norm, cmap=color_map), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots  for matching datasets\n",
    "e = ERDDAP(\n",
    "    server=\"https://cioosatlantic.ca/erddap\", \n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\",\n",
    ")\n",
    "\n",
    "for dataset in matching_datasets:\n",
    "\n",
    "    # Still keeps generating graph after dataset fails for some reason?\n",
    "\n",
    "    e.dataset_id = dataset\n",
    "\n",
    "    e.constraints = {\n",
    "        \"time>=\": start_date - timedelta(days = 2),\n",
    "        \"time<=\": end_date + timedelta(days = 2)\n",
    "    }\n",
    "\n",
    "    e.variables = [\"time\", \"longitude\", \"latitude\", focus_variable]\n",
    "\n",
    "    try:\n",
    "        buoy_data= e.to_pandas(\n",
    "            parse_dates=True,\n",
    "        ).dropna()\n",
    "        buoy_data.plot(x='time (UTC)', y=focus_variable + ' ' + var_units, title=dataset)\n",
    "    except:\n",
    "        print(\"Data does not exist for %s\", dataset) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hurricane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71842d5228d3008246279ae0164097a1e8052b15aaf1b5deabef9a767d14ca29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
